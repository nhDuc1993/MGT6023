{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "008e849d-8b47-4cea-a7a5-b30ea61dd997",
   "metadata": {},
   "source": [
    "# I. Import libraries <a name=\"I\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4868621b-3075-456a-bf50-5eb0365b442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os \n",
    "import warnings\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.eval_measures import mse\n",
    "\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.exponential_smoothing.ets import ETSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2247820-ac31-468c-9dc7-cfe32f1a9922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set printed decimal limit\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Set plot theme\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams['figure.figsize'] = (16, 4)\n",
    "custom_colors = ['#512d6d', '#e6a2b4', '#6b7d96', '#b3cde0']\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=custom_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e482185a-6517-44e3-95f9-119ed5f91e09",
   "metadata": {
    "tags": []
   },
   "source": [
    "# II. Import data <a name=\"II\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32729b7b-192c-4683-90db-562b4d1bfbc0",
   "metadata": {},
   "source": [
    "## 1. Download data  <a name=\"II.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6972c01-45ed-4005-95d7-ad3e257dd886",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = \"1atOZX3YXmxx-_QebbTfndeC6U_DPTL2e\" # ID of the file on Google Drive\n",
    "file_name = 'Updated_data_2021&2022.csv'\n",
    "\n",
    "%run download.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9d1a29-daad-42b7-883e-568fd28bd5b7",
   "metadata": {},
   "source": [
    "## 2. Import data <a name=\"II.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95450574-9006-4ee7-ae21-e998c3b67aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_DIM</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>BET_ACCOUNT_NUM_HASH</th>\n",
       "      <th>AGE</th>\n",
       "      <th>AGE_BAND</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>TENURE_IN_DAYS</th>\n",
       "      <th>RESIDENTIAL_STATE</th>\n",
       "      <th>FOB_RACING_TURNOVER</th>\n",
       "      <th>FOB_SPORT_TURNOVER</th>\n",
       "      <th>PARI_RACING_TURNOVER</th>\n",
       "      <th>PARI_SPORT_TURNOVER</th>\n",
       "      <th>TOTAL_TURNOVER</th>\n",
       "      <th>DIVIDENDS_PAID</th>\n",
       "      <th>GROSS_MARGIN</th>\n",
       "      <th>TICKETS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Fri</td>\n",
       "      <td>13154</td>\n",
       "      <td>67.00</td>\n",
       "      <td>65+</td>\n",
       "      <td>M</td>\n",
       "      <td>11846</td>\n",
       "      <td>WA</td>\n",
       "      <td>37.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1081.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1118.00</td>\n",
       "      <td>443.55</td>\n",
       "      <td>271.25</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Fri</td>\n",
       "      <td>18379</td>\n",
       "      <td>54.00</td>\n",
       "      <td>45-54</td>\n",
       "      <td>M</td>\n",
       "      <td>1884</td>\n",
       "      <td>WA</td>\n",
       "      <td>40.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Fri</td>\n",
       "      <td>559232</td>\n",
       "      <td>63.00</td>\n",
       "      <td>55-64</td>\n",
       "      <td>M</td>\n",
       "      <td>2866</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.00</td>\n",
       "      <td>9.50</td>\n",
       "      <td>2.04</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Fri</td>\n",
       "      <td>698904</td>\n",
       "      <td>69.00</td>\n",
       "      <td>65+</td>\n",
       "      <td>M</td>\n",
       "      <td>2100</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1223.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1223.50</td>\n",
       "      <td>267.91</td>\n",
       "      <td>245.12</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Fri</td>\n",
       "      <td>762921</td>\n",
       "      <td>67.00</td>\n",
       "      <td>65+</td>\n",
       "      <td>M</td>\n",
       "      <td>4766</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DATE_DIM DAY_OF_WEEK  BET_ACCOUNT_NUM_HASH   AGE AGE_BAND GENDER  \\\n",
       "0  2021-01-01         Fri                 13154 67.00      65+      M   \n",
       "1  2021-01-01         Fri                 18379 54.00    45-54      M   \n",
       "2  2021-01-01         Fri                559232 63.00    55-64      M   \n",
       "3  2021-01-01         Fri                698904 69.00      65+      M   \n",
       "4  2021-01-01         Fri                762921 67.00      65+      M   \n",
       "\n",
       "   TENURE_IN_DAYS RESIDENTIAL_STATE  FOB_RACING_TURNOVER  FOB_SPORT_TURNOVER  \\\n",
       "0           11846                WA                37.00                 NaN   \n",
       "1            1884                WA                40.00                 NaN   \n",
       "2            2866                WA                  NaN                 NaN   \n",
       "3            2100                WA                  NaN                 NaN   \n",
       "4            4766                WA                  NaN                 NaN   \n",
       "\n",
       "   PARI_RACING_TURNOVER  PARI_SPORT_TURNOVER  TOTAL_TURNOVER  DIVIDENDS_PAID  \\\n",
       "0               1081.00                  NaN         1118.00          443.55   \n",
       "1                   NaN                  NaN           40.00            0.00   \n",
       "2                 12.00                  NaN           12.00            9.50   \n",
       "3               1223.50                  NaN         1223.50          267.91   \n",
       "4                 17.50                  NaN           17.50            0.00   \n",
       "\n",
       "   GROSS_MARGIN  TICKETS  \n",
       "0        271.25      288  \n",
       "1         40.00        1  \n",
       "2          2.04        5  \n",
       "3        245.12       40  \n",
       "4          3.50        5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File path\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "file_path = os.path.join(parent_dir, 'Data',file_name)\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a8aae-d603-4e9e-9618-aa6e09058340",
   "metadata": {},
   "source": [
    "# III. Clean data <a name=\"III\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f567b0cd-2393-4c20-9bae-c76e6bb23eca",
   "metadata": {},
   "source": [
    "Based on our exploratory data analysis, we apply the similar steps to clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580f4ba-2b92-4445-aaa0-9b2ddf3f90ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    # DATE_DIM: datetime\n",
    "    df['DATE_DIM'] = pd.to_datetime(df['DATE_DIM'], format='%Y-%m-%d')\n",
    "\n",
    "    # BET_ACCOUNT_NUM_HASH: string\n",
    "    df['BET_ACCOUNT_NUM_HASH'] = df['BET_ACCOUNT_NUM_HASH'].astype('O')\n",
    "\n",
    "    # Impute AGE column\n",
    "    df['AGE'].fillna(44, inplace=True)\n",
    "\n",
    "    # More than zero\n",
    "    df = df[df['TOTAL_TURNOVER'] > 0]\n",
    "    \n",
    "    # Drop redundant columns\n",
    "    df.drop(['DAY_OF_WEEK', 'AGE'], axis=1, inplace=True)\n",
    "\n",
    "    # Create RACING_TURNOVER column\n",
    "    df['RACING_TURNOVER'] = df[['FOB_RACING_TURNOVER', 'PARI_RACING_TURNOVER']].sum(axis=1)\n",
    "    \n",
    "    return df.set_index('DATE_DIM')\n",
    "\n",
    "df = clean_data(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cee5194-3973-4dfd-a7ea-a034e6bbb474",
   "metadata": {},
   "source": [
    "# IV. Aggregate and feature engineering <a name=\"IV\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4abb80-0859-406a-8654-36a63f921d00",
   "metadata": {},
   "source": [
    "We create a dataframe containing all demographic categorical factors: `AGE_BAND`, `GENDER`, `RESIDENTIAL_STATE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9f2db8-f4c4-4c27-8bf3-afdcbf156339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create customer demographic info dataframe\n",
    "def cus_aggregate(df):\n",
    "    cus_df = df.groupby('BET_ACCOUNT_NUM_HASH').agg({'AGE_BAND':min, 'GENDER': min, 'RESIDENTIAL_STATE':min})\n",
    "    return cus_df\n",
    "\n",
    "cus_df = cus_aggregate(df)\n",
    "cus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c0b649-074c-445d-b202-88eeb7403d4e",
   "metadata": {},
   "source": [
    "We extract behaviorial variables that could impact future spending:\n",
    "- Frequency ([0-1])\n",
    "- Racing spending ratio ([0-1])\n",
    "- Dividends paid ratio (>0)\n",
    "- Average turnover per day\n",
    "- Average tickets purchased per day\n",
    "\n",
    "We go back 1 week, 4 weeks and 12 weeks. Along with demographic data, here is the list of columns to be created and treated as independent variables.\n",
    "\n",
    "Out predicted (dependent) variables will be the average turnover per day for the next 4 week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf89004e-d052-4ff9-95bc-a742eb869407",
   "metadata": {},
   "source": [
    "| Column | Description |\n",
    "|-----------------|-----------------|\n",
    "| AGE_BAND | Customer’s age band as of Wager date | \n",
    "| GENDER | Customer’s gender (M, F, U) | \n",
    "| RESIDENTIAL_STATE | Residential state where the customer resides | \n",
    "| AVG_FREQ_12 | Betting frequency of the last 12 weeks [0-1] |\n",
    "| RACING_RATIO_12 | Racing spending ratio of the last 12 weeks [0-1]|\n",
    "| AVG_TURNOVER_12 | Average turnover per day for the last 12 weeks|\n",
    "| DIVIDENDS_RATIO_12 |Dividends paid of the last 12 weeks|\n",
    "| AVG_TICKETS_12 |Average tickets purchased per day for the last 12 weeks|\n",
    "| AVG_FREQ_4 | Betting frequency of the last 4 weeks [0-1] |\n",
    "| RACING_RATIO_4 | Racing spending ratio of the last 4 weeks [0-1]|\n",
    "| AVG_TURNOVER_4 | Average turnover per day for the last 4 weeks|\n",
    "| DIVIDENDS_RATIO_4 |Dividends paid of the last 4 weeks|\n",
    "| AVG_TICKETS_4 |Average tickets purchased per day for the last 4 weeks|\n",
    "| AVG_FREQ_1 | Betting frequency of the last week [0-1] |\n",
    "| RACING_RATIO_1 | Racing spending ratio of the last week [0-1]|\n",
    "| AVG_TURNOVER_1 | Average turnover per day for the last week|\n",
    "| DIVIDENDS_RATIO_1 |Dividends paid of the last week|\n",
    "| AVG_TICKETS_1 |Average tickets purchased per day for the last week|\n",
    "| AVG_TURNOVER |Average turnover per day for the next 4 weeks|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac717412-eeb5-4324-9830-6fa86fbdb63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekly_aggregate(df, date='2021-05-10', weeks=4):\n",
    "    # Filtered period\n",
    "    past_date = (datetime.strptime(date, '%Y-%m-%d') - timedelta(weeks=weeks)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Aggregate\n",
    "    agg_df = df[(df.index >= past_date ) & (df.index < date)].groupby('BET_ACCOUNT_NUM_HASH').agg({\n",
    "        'BET_ACCOUNT_NUM_HASH': np.size,\n",
    "        'TENURE_IN_DAYS' : max,\n",
    "        'RACING_TURNOVER': sum,\n",
    "        'TOTAL_TURNOVER' : sum,\n",
    "        'DIVIDENDS_PAID' : sum,\n",
    "        'TICKETS' : sum\n",
    "    })\n",
    "    \n",
    "    # Create ratio columns\n",
    "    agg_df['RACING_TURNOVER'] = agg_df['RACING_TURNOVER'] / agg_df['TOTAL_TURNOVER']\n",
    "    agg_df['DIVIDENDS_PAID'] = agg_df['DIVIDENDS_PAID'] / agg_df['TOTAL_TURNOVER']\n",
    "\n",
    "    # Create average columns\n",
    "    agg_df[['BET_ACCOUNT_NUM_HASH', 'TOTAL_TURNOVER', 'TICKETS']] = agg_df[['BET_ACCOUNT_NUM_HASH', 'TOTAL_TURNOVER', 'TICKETS']] / (weeks*7)\n",
    "    \n",
    "    agg_df.columns = ['AVG_FREQ_' + str(weeks), \n",
    "                     'TENURE_IN_DAYS_' + str(weeks), \n",
    "                     'RACING_RATIO_' + str(weeks),\n",
    "                     'AVG_TURNOVER_' + str(weeks),\n",
    "                     'DIVIDENDS_RATIO_' + str(weeks),\n",
    "                     'AVG_TICKETS_' + str(weeks)]\n",
    "    \n",
    "    return agg_df\n",
    "\n",
    "def total_aggregate(df, date='2021-05-10'):\n",
    "    # Prediction (4 weeks after the current week)\n",
    "    future_date = (datetime.strptime(date, '%Y-%m-%d') + timedelta(weeks=4)).strftime('%Y-%m-%d')\n",
    "    pred = df[ (df.index >= date ) & (df.index < future_date)].groupby('BET_ACCOUNT_NUM_HASH').TOTAL_TURNOVER.sum().to_frame() / 28\n",
    "    pred.columns = ['AVG_TURNOVER']\n",
    "    \n",
    "    # Aggregate\n",
    "    train_12 = weekly_aggregate(df,date=date, weeks=12)\n",
    "    train_4 = weekly_aggregate(df,date=date, weeks=4)\n",
    "    train_1 = weekly_aggregate(df,date=date, weeks=1)\n",
    "    \n",
    "    # Filter new customers\n",
    "    train_12 = train_12[train_12['TENURE_IN_DAYS_12'] >= 84]\n",
    "    \n",
    "    # Join data\n",
    "    train = pd.merge(train_12, train_4, left_index=True, right_index=True, how='left')\n",
    "    train = pd.merge(train, train_1, left_index=True, right_index=True, how='left')\n",
    "    train = pd.merge(train, pred, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    # Drop TENURE_IN_DAYS columns\n",
    "    train.drop(['TENURE_IN_DAYS_12', 'TENURE_IN_DAYS_4', 'TENURE_IN_DAYS_1'], axis=1, inplace=True)\n",
    "    \n",
    "    # Fill na\n",
    "    train.fillna(0, inplace=True)\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f35e96-8512-4ac6-9d4b-855c0c5d943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 2021-05-10'\n",
    "date='2021-05-10'\n",
    "train = total_aggregate(df, date=date)\n",
    "\n",
    "# Join with cus_df to get categorical data\n",
    "train = pd.merge(train, cus_df, left_index=True, right_index=True, how='left')\n",
    "\n",
    "# Preview\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8d1249-d29d-4d58-a9f7-ac5fae5ff390",
   "metadata": {},
   "source": [
    "# V. Predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c146eec-67cc-4a01-92c9-2bf5579ff7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "corr_df = train.corr()\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "cmap = sns.light_palette(\"#512d6d\", as_cmap=True)\n",
    "sns.heatmap(corr_df, cmap=cmap, vmin=0, vmax=1 , annot=True, fmt=\".2f\")\n",
    "plt.title(\"Correllation Heatmap\")\n",
    "\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e404cc-0fe7-48fe-a240-6db214c504b9",
   "metadata": {},
   "source": [
    "## 1. Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efec2a9c-b792-48c8-8d79-2cb8e210cc58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create X and y\n",
    "X = train.drop('AVG_TURNOVER', axis=1)\n",
    "y = train['AVG_TURNOVER']\n",
    "\n",
    "# Evaluation dataframe\n",
    "eva_df = pd.DataFrame(columns = [\"Model\", \"MSE\", \"R2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71031174-7b22-4c79-ae3c-cf0aac6cc39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose independent variables\n",
    "cat_cols = ['AGE_BAND', 'GENDER', 'RESIDENTIAL_STATE']\n",
    "\n",
    "num_cols = ['AVG_FREQ_12','RACING_RATIO_12','AVG_TURNOVER_12','DIVIDENDS_RATIO_12', 'AVG_TICKETS_12', 'AVG_FREQ_4', 'RACING_RATIO_4', \n",
    "            'AVG_TURNOVER_4','DIVIDENDS_RATIO_4','AVG_TICKETS_4','AVG_FREQ_1','RACING_RATIO_1','AVG_TURNOVER_1','DIVIDENDS_RATIO_1','AVG_TICKETS_1']\n",
    "\n",
    "# Transform columns\n",
    "one_hot_encoder = OneHotEncoder(sparse = False)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"cat\", one_hot_encoder, cat_cols),\n",
    "    (\"num\", \"passthrough\", num_cols),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3eda50-7000-4dcc-b351-24eae383e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform\n",
    "X_trans = full_pipeline.fit_transform(X)\n",
    "y = y.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757ff91c-c1c4-4ec5-befd-e68657298adf",
   "metadata": {},
   "source": [
    "### a. Simple linear regression with statsmodel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efff9f0e-05c3-4dfc-89b4-1c15d4c3c866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add constant term\n",
    "X_trans = sm.add_constant(X_trans)\n",
    "\n",
    "# train and val set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trans, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "model = sm.OLS(y_train, X_train) \n",
    "results = model.fit()\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46655ecb-fca9-4c17-891a-4073f8a8a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "mse = results.mse_resid\n",
    "R2 = results.rsquared\n",
    "\n",
    "eva_df = eva_df.append({\"Model\": \"Simple Linear Regression\", \"MSE\" : mse, \"R2\" : R2},ignore_index=True)\n",
    "eva_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f327e0f2-b359-4fd6-af09-38497b8202c4",
   "metadata": {},
   "source": [
    "Positive points of the model:\n",
    "- Good fit: R-squared and Adj. R-squared are relatively high\n",
    "- No autoregression ( Durbin-Watson close to 2)\n",
    "\n",
    "Problems with the model:\n",
    "- Multicolinearity (high Cond. No.)\n",
    "- Insignificant variables\n",
    "- Heteroskedascity\n",
    "- Residuals significently deviate from normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5c0818-6fbc-4978-b2d7-806fc065a175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred = results.predict(X_val)\n",
    "e = y_val.flatten() - y_pred\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1,2, figsize=(16,6))\n",
    "\n",
    "axes[0].scatter(y_val, y_pred)\n",
    "axes[0].set_xlabel(\"Real value\")\n",
    "axes[0].set_ylabel(\"Predicted value\")\n",
    "axes[0].set_title(\"Scatter plot: Real turnover vs. Predicted turnover\") \n",
    "\n",
    "axes[1].scatter(y_val, e)\n",
    "axes[1].set_xlabel(\"Real value\")\n",
    "axes[1].set_ylabel(\"Residuals\")\n",
    "axes[1].set_title(\"Scatter plot: Real turnover vs. Residuals\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a195fc5-c31a-44c7-85c9-d841ff7559cb",
   "metadata": {},
   "source": [
    "### b. With sklearn and cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ac68c9-e0bc-43cd-8961-b6b138ea0d45",
   "metadata": {},
   "source": [
    "We use k-fold cross validation to eliminate selection bias. MSE above might be more positive because the validation set is within lower range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843f2887-9805-445d-9147-7c7b3faf2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform\n",
    "X_trans = full_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9412afd2-6231-4532-87a0-0cfdc8b7200f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit model\n",
    "lin_reg = LinearRegression(fit_intercept=True)\n",
    "\n",
    "# K-fold cross validation with k=10\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = cross_validate(lin_reg, X_trans, y, cv=kfold, scoring = ['neg_mean_squared_error','r2'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7afb7f4-b47a-4490-b0c6-d75105a05e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding metrics to the evaluation dataframe\n",
    "mse = -scores['test_neg_mean_squared_error'].mean()\n",
    "R2 = scores['test_r2'].mean()\n",
    "\n",
    "eva_df = eva_df.append({\"Model\": \"Simple Linear Regression with cross validation\", \"MSE\" : mse, \"R2\" : R2},ignore_index=True)\n",
    "eva_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4b4474-9dfa-45a2-bbe0-b44014dc62c6",
   "metadata": {},
   "source": [
    "### c. Regularization with LASSO and Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8db4f5-927c-4827-8288-97a9f6b14813",
   "metadata": {},
   "source": [
    "#### LASSO Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7922172e-3962-4e44-9cf1-7d109d698e55",
   "metadata": {},
   "source": [
    "LASSO regression, also known as L1 regularization, is a popular technique in statistical modeling and machine learning used for variable selection and regularization. It is an extension of linear regression that adds a penalty term to the ordinary least squares objective function. It helps eliminating insignificant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fec387-3b14-4646-97af-6591aa9e85c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model instance\n",
    "lasso_reg = Lasso()\n",
    "\n",
    "# Define the alpha values to be tested\n",
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "# GridSearchCV\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "lasso_grid = GridSearchCV(estimator=lasso_reg, param_grid={'alpha': alphas}, cv=kfold, return_train_score=True)\n",
    "\n",
    "# Fit\n",
    "lasso_grid.fit(X_trans,y)\n",
    "\n",
    "# Alpha\n",
    "alpha = lasso_grid.best_params_['alpha']\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7374486c-af98-4b80-bbf5-d29b12bf9990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold cross validation with k=10\n",
    "lasso_reg = Lasso(alpha=alpha)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = cross_validate(lasso_reg, X_trans, y, cv=kfold, scoring = ['neg_mean_squared_error','r2'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03261544-8803-4ead-b565-400d62072ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding metrics to the evaluation dataframe\n",
    "mse = -scores['test_neg_mean_squared_error'].mean()\n",
    "R2 = scores['test_r2'].mean()\n",
    "\n",
    "eva_df = eva_df.append({\"Model\": \"LASSO regression\", \"MSE\" : mse, \"R2\" : R2},ignore_index=True)\n",
    "eva_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe743ac-3051-4d94-8f14-89bad1b6216c",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a0a25a-91f7-4286-b25c-2a68357456fb",
   "metadata": {},
   "source": [
    "Ridge regression, also known as L2 regularization, is another widely used technique for linear regression that addresses the limitations of ordinary least squares. It is similar to lasso regression but uses a different penalty term. It shrinks down insignificant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc76a001-a6c3-4777-bbc6-5ee0a4ddd0e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a model instance\n",
    "ridge_reg = Ridge()\n",
    "\n",
    "# Define the alpha values to be tested\n",
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "# GridSearchCV\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "ridge_grid = GridSearchCV(estimator=ridge_reg, param_grid={'alpha': alphas}, cv=kfold, return_train_score=True)\n",
    "\n",
    "# Fit\n",
    "ridge_grid.fit(X_trans,y)\n",
    "\n",
    "# Alpha\n",
    "alpha = ridge_grid.best_params_['alpha']\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25cb6ab-0cbd-48b9-966f-ed20d9073051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold cross validation with k=10\n",
    "ridge_reg = Ridge(alpha=alpha)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = cross_validate(ridge_reg, X_trans, y, cv=kfold, scoring = ['neg_mean_squared_error','r2'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa458efa-f3de-4336-9bfe-433b51c59579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding metrics to the evaluation dataframe\n",
    "mse = -scores['test_neg_mean_squared_error'].mean()\n",
    "R2 = scores['test_r2'].mean()\n",
    "\n",
    "eva_df = eva_df.append({\"Model\": \"Ridge regression\", \"MSE\" : mse, \"R2\" : R2},ignore_index=True)\n",
    "eva_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b85f71-4610-468e-baf2-f778141a7487",
   "metadata": {},
   "source": [
    "### d. Linear Regression with PCA transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7964b307-b3ec-4964-a507-a7b077cb2f0e",
   "metadata": {},
   "source": [
    "Principal component analysis (PCA) is a popular algorithm to reduce data dimensions. It helps eradicating multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5457b91-f021-4eef-85f0-1b7e10462753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaling before PCA\n",
    "std_scaler = StandardScaler()\n",
    "X_scaled = std_scaler.fit_transform(X_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df345656-17af-479e-8d0b-eec09c6d428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "X_pca = pca.transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d726720a-62cc-4dbd-87ee-04c6525d85e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained variance ratio\n",
    "explained_var_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(range(1,28),np.cumsum(explained_var_ratio))\n",
    "plt.title('Cumulative explained variance')\n",
    "plt.xlabel('Component')\n",
    "plt.ylabel('Explained Variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d9b866-53f2-4c47-9fc0-447bc8af9552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We choose number of components to be 14 that explains 90% of the variance of the original data\n",
    "X_pca = X_pca[:,:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afb06f8-a642-46b7-a93b-cce11f94efac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "lin_reg = LinearRegression(fit_intercept=True)\n",
    "\n",
    "# K-fold cross validation with k=10\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = cross_validate(lin_reg, X_pca, y, cv=kfold, scoring = ['neg_mean_squared_error','r2'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dbd2b5-d476-46d4-940d-88b6092e644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding metrics to the evaluation dataframe\n",
    "mse = -scores['test_neg_mean_squared_error'].mean()\n",
    "R2 = scores['test_r2'].mean()\n",
    "\n",
    "eva_df = eva_df.append({\"Model\": \"Linear Regression with PCA\", \"MSE\" : mse, \"R2\" : R2},ignore_index=True)\n",
    "eva_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70026cc2-3735-477f-ae7e-5666ea57d103",
   "metadata": {},
   "source": [
    "### e. Regression with Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a2047e-84e9-4f6e-88d6-02aca5ba3a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,5,figsize=(16,12))\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(5):\n",
    "        axes[i,j].scatter(X.iloc[:,i*5 + j], y)\n",
    "        axes[i,j].set_title(X.columns[i*5+ j]) \n",
    "        axes[i,j].set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f31dc7a-bca5-428d-8bc2-4048199d6c49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_log = np.log(X[['AVG_TURNOVER_12','AVG_TURNOVER_4','AVG_TURNOVER_1']]+1)\n",
    "y_log = np.log(y+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3593275f-099b-4353-a016-58eeb88f772e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(y_log, X_log) \n",
    "results = model.fit()\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b8b6a-5800-421d-ab74-5a7adb5b7f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.exp(results.predict(X_log))-1\n",
    "mse = mean_squared_error(y.flatten(), y_pred)\n",
    "R2 = r2_score(y.flatten(), y_pred)\n",
    "\n",
    "eva_df = eva_df.append({\"Model\": \"Log-Log Regression\", \"MSE\" : mse, \"R2\" : R2},ignore_index=True)\n",
    "eva_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3357d3c6-3ca9-4e26-b204-180cff1c8f37",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Regression tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a9d6d7-717c-40de-8db5-3b7e03763347",
   "metadata": {},
   "source": [
    "A decision tree regressor works by constructing a tree-like model where each internal node represents a decision based on a specific feature and a corresponding threshold value. The leaf nodes of the tree contain the predicted output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3c38b4-70b0-447f-a12b-998929d1e0f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth' : range(3,26),\n",
    "    'min_weight_fraction_leaf' : [0.03,0.05,0.10]\n",
    "}\n",
    "\n",
    "tree_reg_grid = GridSearchCV(estimator=tree_reg, param_grid=param_grid, cv=10)\n",
    "tree_reg_grid.fit(X_trans, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd35cc56-ff8e-454a-a837-3ec201c1d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = tree_reg_grid.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bef8dcc-2a2c-4362-859c-a92054050375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold cross validation with k=10\n",
    "tree_reg = DecisionTreeRegressor(**best_params)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = cross_validate(tree_reg, X_trans, y, cv=kfold, scoring = ['neg_mean_squared_error','r2'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130676f3-6803-4dec-88bf-6e52148c0cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to \n",
    "mse = -scores['test_neg_mean_squared_error'].mean()\n",
    "R2 = scores['test_r2'].mean()\n",
    "\n",
    "eva_df = eva_df.append({\"Model\": \"Decision tree regressor\", \"MSE\" : mse, \"R2\" : R2},ignore_index=True)\n",
    "eva_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da4c6bd-4f53-471e-b813-62264de88b32",
   "metadata": {},
   "source": [
    "## 3. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5ff62-b0f7-4f64-aad2-05b5e036aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor(n_estimators=500, max_depth= 10, min_weight_fraction_leaf= 0.05, random_state=42)\n",
    "rf_reg.fit(X_trans, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9df4af-8e8b-439d-9a28-d3ebd5e132dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_reg.predict(X_trans)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "R2 = r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c5aff3-044e-427b-9c27-16c1321a88ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_df = eva_df.append({\"Model\": \"Random forest regressor\", \"MSE\" : mse, \"R2\" : R2},ignore_index=True)\n",
    "eva_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5293ee-ac78-4ca5-9066-cc2821446879",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(y,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ed8a81-a4a7-425d-836e-61855607fc38",
   "metadata": {},
   "source": [
    "# VI. Time series model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5678b5-4ef5-42c3-b7b9-7ac888fe8237",
   "metadata": {},
   "source": [
    "## 1. Exponential Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798f7695-cceb-48c1-97c2-54c52d4724da",
   "metadata": {},
   "source": [
    "Triple Exponential Smoothing, also known as Holt-Winters' Triple Exponential Smoothing, is a time series forecasting method that extends the concept of exponential smoothing to capture both trend and seasonality in the data. It is a popular technique used in various industries to make accurate predictions for time-dependent data.\n",
    "\n",
    "In this particular case, daily trend can be acting at high variance. Therefore, we choose weekly granularity level. We run a triple exponential smoothing model with trend factor on all historical data and predict the next 4 week turnover spending of a customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8b11bb-d161-464b-a075-a592dd4c4221",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2021-05-10'\n",
    "future_date = (datetime.strptime(date, '%Y-%m-%d') + timedelta(weeks=4)).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24603e6-858f-4ff6-a939-31f4760fbcd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = df[df.index < date]\n",
    "test_df = df[(df.index >= date) & (df.index < future_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aa1cd2-4bd5-4587-96bf-78d1682b4e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "cus = train_df.groupby('BET_ACCOUNT_NUM_HASH',as_index=False).TENURE_IN_DAYS.max()\n",
    "legitimate_cus = cus.loc[cus['TENURE_IN_DAYS'] >= 28, 'BET_ACCOUNT_NUM_HASH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afba75a-cffa-4a0f-92f8-3043d3d67efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['BET_ACCOUNT_NUM_HASH'].isin(legitimate_cus)]\n",
    "test_df = test_df[test_df['BET_ACCOUNT_NUM_HASH'].isin(legitimate_cus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86da65ac-ec78-4300-8a28-f97af933ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns = ['BET_ACCOUNT_NUM_HASH', 'real', 'pred'])\n",
    "X_test = test_df.groupby('BET_ACCOUNT_NUM_HASH').TOTAL_TURNOVER.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac576c83-211f-4f28-8cff-c92b7c96277f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in legitimate_cus: \n",
    "    cus_df = train_df[train_df['BET_ACCOUNT_NUM_HASH'] == i]\n",
    "\n",
    "    X_train = cus_df.resample('W').TOTAL_TURNOVER.sum()\n",
    "\n",
    "    X_train = X_train.reindex(pd.date_range(start='2021-01-03',end=future_date, freq=\"W\")).fillna(0)\n",
    "\n",
    "    exp_smth = ETSModel(X_train, trend = \"add\", freq='W')\n",
    "\n",
    "    result = exp_smth.fit()\n",
    "\n",
    "    start = X_train.index[-1] + pd.DateOffset(7)\n",
    "    end = X_train.index[-1] + pd.DateOffset(28)\n",
    "\n",
    "    X_forecast = result.predict(start=start, end=end)\n",
    "\n",
    "    try:\n",
    "        real = X_test[i]\n",
    "    except:\n",
    "        real = 0\n",
    "\n",
    "    pred = X_forecast.sum()\n",
    "\n",
    "    res = res.append({'BET_ACCOUNT_NUM_HASH' : i, 'real':real, 'pred': pred}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ff3f98-db66-423a-9fd3-724029bae08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c0b4e2-f0c0-4966-9ce3-9dcace72e682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab34e820-f0fb-4aeb-a395-dde2ddaf2e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647bc89e-c6af-4362-9d97-0a8ee4cbf31c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bbf59a-6f54-44b7-a936-dab9d3c4b11e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d27807-9a80-43dc-8e34-4e6ccd422178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e3f542-4f6c-4a74-abfe-176ed7adc330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe3148b-344c-4118-a217-ec0d2dc2ea22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bfbfb5-3340-4f12-8b76-cf063a29f26d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a38f3aa-c947-4343-97ec-d05d86fc882b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe9ff5e-7735-4bc5-8faa-eb6110b5a865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbbeea9-a1b2-4546-8bba-93d017b4ca87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
